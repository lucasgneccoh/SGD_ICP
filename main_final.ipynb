{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "htovwa9SD5XU",
        "pJsUnC_JCy5M",
        "HvxX0IpkcoN7",
        "MamlhJFkDVc3",
        "FdICxac5DZnz",
        "s7qh7d2LJ3EH",
        "osHeYQYWFqpp"
      ],
      "authorship_tag": "ABX9TyM22b/C5pjly9QETTnQIQoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53ad59ae73db4beab5e0a414bdea08b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c97185726e52473698fcd3dfa95f10f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0c20aef67914a92866efee3ae28c3c0",
              "IPY_MODEL_917b0f73081b4e73b838835648d1c1bb"
            ]
          }
        },
        "c97185726e52473698fcd3dfa95f10f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0c20aef67914a92866efee3ae28c3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c476c14628d414bac9504a0b92e4531",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_957dac19e8584c6aa38d61bab6884ae1"
          }
        },
        "917b0f73081b4e73b838835648d1c1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a47e84eb56ae4f2fae697618dd30520f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [14:13&lt;00:00, 17.06s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd33650d6a6a46aebec8396a7617e6e0"
          }
        },
        "2c476c14628d414bac9504a0b92e4531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "957dac19e8584c6aa38d61bab6884ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a47e84eb56ae4f2fae697618dd30520f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd33650d6a6a46aebec8396a7617e6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasgneccoh/SGD_ICP_PY/blob/main/main_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htovwa9SD5XU"
      },
      "source": [
        "# Install authors implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTSbikgEGbfl"
      },
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "!git clone https://bitbucket.org/fafz/sgd_icp.git\n",
        "!sudo apt install libeigen3-dev\n",
        "!sudo apt install libpcl-dev\n",
        "%cd /content/sgd_icp\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake -DCMAKE_BUILD_TYPE=Release /content/sgd_icp\n",
        "!make"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJsUnC_JCy5M"
      },
      "source": [
        "# Project - SGD ICP in python\n",
        "Excecute this cell to import modules and define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW7ep3CSuFxb"
      },
      "source": [
        "# Clone the repository in the Colab drive\n",
        "# Build and Install pypcd to deal with pcd format clouds\n",
        "%%capture\n",
        "%cd /content\n",
        "!git clone https://github.com/lucasgneccoh/SGD_ICP_PY.git\n",
        "!pip install lzf\n",
        "'''\n",
        "Setup pypcd\n",
        "'''\n",
        "%cd /content/SGD_ICP_PY/pypcd/\n",
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGN9pzt8NslB",
        "outputId": "e77e9c32-b7d6-4f27-cead-da453238aa1f"
      },
      "source": [
        "%cd /content/SGD_ICP_PY/sgd_icp_python\n",
        "import os\n",
        "import numpy as np\n",
        "from pypcd import pypcd as pcd\n",
        "from google.colab import files\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "# Import numpy package and name it \"np\"\n",
        "import numpy as np\n",
        "\n",
        "# Import library to plot in python\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Import functions from scikit-learn\n",
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "# Import functions to read and write ply files\n",
        "from ply_utils import write_ply, read_ply\n",
        "from visu import show_ICP\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def quaternion_rotation_matrix(Q):\n",
        "    \"\"\"\n",
        "    Covert a quaternion into a full three-dimensional rotation matrix.\n",
        " \n",
        "    Input\n",
        "    :param Q: A 4 element array representing the quaternion (q0,q1,q2,q3) \n",
        " \n",
        "    Output\n",
        "    :return: A 3x3 element matrix representing the full 3D rotation matrix. \n",
        "             This rotation matrix converts a point in the local reference \n",
        "             frame to a point in the global reference frame.\n",
        "    \"\"\"\n",
        "    # Extract the values from Q\n",
        "    q0 = Q[0]\n",
        "    q1 = Q[1]\n",
        "    q2 = Q[2]\n",
        "    q3 = Q[3]\n",
        "     \n",
        "    # First row of the rotation matrix\n",
        "    r00 = 2 * (q0 * q0 + q1 * q1) - 1\n",
        "    r01 = 2 * (q1 * q2 - q0 * q3)\n",
        "    r02 = 2 * (q1 * q3 + q0 * q2)\n",
        "     \n",
        "    # Second row of the rotation matrix\n",
        "    r10 = 2 * (q1 * q2 + q0 * q3)\n",
        "    r11 = 2 * (q0 * q0 + q2 * q2) - 1\n",
        "    r12 = 2 * (q2 * q3 - q0 * q1)\n",
        "     \n",
        "    # Third row of the rotation matrix\n",
        "    r20 = 2 * (q1 * q3 - q0 * q2)\n",
        "    r21 = 2 * (q2 * q3 + q0 * q1)\n",
        "    r22 = 2 * (q0 * q0 + q3 * q3) - 1\n",
        "     \n",
        "    # 3x3 rotation matrix\n",
        "    rot_matrix = np.array([[r00, r01, r02],\n",
        "                           [r10, r11, r12],\n",
        "                           [r20, r21, r22]])\n",
        "                            \n",
        "    return rot_matrix\n",
        "\n",
        "def pitch_roll_yaw(ax, ay, az):\n",
        "  cx, sx = np.cos(ax), np.sin(ax)\n",
        "  cy, sy = np.cos(ay), np.sin(ay)\n",
        "  cz, sz = np.cos(az), np.sin(az)\n",
        "  \n",
        "  R = np.array([[cz*cy, cz*sx*sy-sz*cx, cz*sx*sy+sz*sy],\n",
        "                [sz*cy, sz*sx*sy+cz*cx, sz*sx*sy-cz*sx],\n",
        "                [-sy, cy*sx, cy*cx]])\n",
        "  return R\n",
        "\n",
        "def d_R(ax, ay, az):\n",
        "  cx, sx = np.cos(ax), np.sin(ax)\n",
        "  cy, sy = np.cos(ay), np.sin(ay)\n",
        "  cz, sz = np.cos(az), np.sin(az)\n",
        "  \n",
        "  d_roll = np.array([[0, 0, 0],\n",
        "                [cx*sy*cz-sx*sz, -cx*sy*sz-sx*cz, -cx*cy],\n",
        "                [sx*sy*cz + cx*sz, -sx*sy*sz+cx*cz,-sx*cy]])\n",
        "  \n",
        "  d_pitch = np.array([[-sy*cz, sy*sz, cy],\n",
        "                [sx*cy*cz, -sx*cy*sz, sx*sy],\n",
        "                [-cx*cy*cz, cx*cy*sz, -cx*sy]])\n",
        "  \n",
        "  d_yaw = np.array([[-cy*sz, -cy*cz, 0],\n",
        "                [-sx*sy*sz+cx*cz, -sx*sy*cz-cx*sz, 0],\n",
        "                [cx*sy*sz + sx*cz, cx*sy*cz-sx*sz, 0]])\n",
        "  return d_roll, d_pitch, d_yaw\n",
        "\n",
        "\n",
        "def add_noise(pc, mean, std):\n",
        "  return pc + np.random.normal(loc=mean, scale=std, size=pc.shape)\n",
        "\n",
        "def apply_transform(pc, R, t):\n",
        "  if isinstance(pc, pcd.PointCloud):\n",
        "    cloud = np.vstack([pc.pc_data['x'], pc.pc_data['y'], pc.pc_data['z']])\n",
        "    cloud = R @ cloud + t.reshape(-1,1)\n",
        "    for a, i in zip(['x', 'y', 'z'], range(3)):\n",
        "      pc.pc_data[a] = cloud[i,:]\n",
        "  else:\n",
        "    pc = R @ pc +  t.reshape(-1,1)    \n",
        "  return pc\n",
        "\n",
        "def apply_transform_from_theta(pc, theta):\n",
        "  R, T = theta_to_tranformation(theta)\n",
        "  return apply_transform(pc, R, T)\n",
        "\n",
        "\n",
        "def roll_pitch_yaw(ax, ay, az):\n",
        "  cx, sx = np.cos(ax), np.sin(ax)\n",
        "  cy, sy = np.cos(ay), np.sin(ay)\n",
        "  cz, sz = np.cos(az), np.sin(az)\n",
        "  \n",
        "  Rx = np.array([[1.0,0.0,0.0],\n",
        "                 [0.0, cx, -sx],\n",
        "                 [0.0, sx, cx]])\n",
        "  Ry = np.array([[cy,0.0,sy],\n",
        "                 [0.0, 1.0, 0.0],\n",
        "                 [-sy, 0.0, cy]])\n",
        "  Rz = np.array([[cz,-sz,0.0],\n",
        "                 [sz, cz, 0.0],\n",
        "                 [0.0, 0.0, 1.0]])\n",
        "  return Rx @ Ry @ Rz\n",
        "\n",
        "def theta_to_tranformation(theta):\n",
        "  R, T = roll_pitch_yaw(*theta[3:]), theta[:3].copy().reshape(-1,1)\n",
        "  return R, T\n",
        "\n",
        "def gradient_wrt_theta(source, ref, theta):\n",
        "  R, T = theta_to_tranformation(theta)\n",
        "  ins = (R @ source + T) - ref # 3 x M\n",
        "  # w.r.t T, it is already in ins\n",
        "  # w.r.t R  \n",
        "  d = list(d_R(*theta[3:]))\n",
        "  D = np.array([((a @ source)*ins).sum(0).mean() for a in d])\n",
        "  # print(D)\n",
        "\n",
        "  return np.hstack([2*D, 2*ins.mean(axis=1)]) \n",
        "\n",
        "def gradient_wrt_R_T(source, ref, R, T):\n",
        "  ins = (R @ source + T) - ref # 3 x M  \n",
        "  gradR, M = np.zeros_like(R), source.shape[1]\n",
        "  for i, s in zip(ins.T, source.T):\n",
        "    gradR += 1.0/M * (i.reshape(3,1) @ s.reshape(1,3))\n",
        "  gradT = (ins.mean(axis=1)).reshape(3,1)\n",
        "  return 2*gradR, 2*gradT \n",
        "\n",
        "def read_pcd(path):\n",
        "  pc = pcd.point_cloud_from_path(path)\n",
        "  return np.vstack([pc.pc_data['x'], pc.pc_data['y'], pc.pc_data['z']])\n",
        "\n",
        "def dropout(cloud, drop_prop):\n",
        "  ind = (np.random.uniform(size=cloud.shape[1])>drop_prop)\n",
        "  return cloud[:,ind]\n",
        "\n",
        "def normalize(cloud, eps=1e-4, and_center=True):\n",
        "  M, m = cloud.max(1), cloud.min(1)\n",
        "  dif = np.maximum(M-m,eps).reshape(-1,1)\n",
        "  normal = (cloud - m.reshape(-1,1))/dif\n",
        "  if and_center:\n",
        "    normal = normal - normal.mean(axis=1).reshape(-1,1)\n",
        "  return normal\n",
        "\n",
        "def crop_cloud_sphere(cloud, radius):\n",
        "  ind = (np.linalg.norm(cloud, axis=0)<radius)\n",
        "  return cloud[:,ind]\n",
        "\n",
        "def save_whole_cloud_pcd(paths_in, path_out):\n",
        "  start = True\n",
        "  whole = None\n",
        "  for path_in in paths_in:\n",
        "    pc = pcd.point_cloud_from_path(path_in)\n",
        "    meta = pc.get_metadata()\n",
        "    trans = np.array(meta['viewpoint'][:3])\n",
        "    rot = quaternion_rotation_matrix(meta['viewpoint'][3:]).T\n",
        "    \n",
        "    cloud = np.vstack([pc.pc_data['x'], pc.pc_data['y'], pc.pc_data['z']])\n",
        "    \n",
        "    rotated = rot.T @ cloud + trans.reshape(-1,1)\n",
        "    \n",
        "    pc.pc_data['x'] = rotated[0,:]\n",
        "    pc.pc_data['y'] = rotated[1,:]\n",
        "    pc.pc_data['z'] = rotated[2,:]\n",
        "    if start:\n",
        "      start = False\n",
        "      whole = pc\n",
        "    else:\n",
        "      whole = pcd.cat_point_clouds(whole, pc)\n",
        "      \n",
        "  whole.save_pcd(path_out)\n",
        "\n",
        "\n",
        "def plot_clouds(source, ref, test, drop_rate = 0.9, size=1, careful = True):\n",
        "  sp = dropout(source, drop_rate)\n",
        "  rp = dropout(ref, drop_rate)  \n",
        "  tp = dropout(test, drop_rate)\n",
        "  if careful and max(sp.shape[1], rp.shape[1], tp.shape[1]) > 400:\n",
        "    print(\"Careful mode: Too many points, performing more down sampling\")\n",
        "    sp = dropout(sp, 1- 400.0/sp.shape[1])\n",
        "    rp = dropout(rp, 1- 400.0/rp.shape[1])\n",
        "    tp = dropout(tp, 1- 400.0/tp.shape[1])\n",
        "\n",
        "  df = pd.concat([pd.DataFrame(data={'cloud':'source','x':sp[0,:],'y':sp[1,:],'z':sp[2,:]}),\n",
        "                  pd.DataFrame(data={'cloud':'ref','x':rp[0,:],'y':rp[1,:],'z':rp[2,:]}),\n",
        "                  pd.DataFrame(data={'cloud':'icp','x':tp[0,:],'y':tp[1,:],'z':tp[2,:]})\n",
        "                  ])\n",
        "  df['size'] = size\n",
        "  fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
        "                color='cloud')\n",
        "  fig.show()\n",
        "\n",
        "def rotation_matrix(roll, pitch, yaw, device='cpu'):  \n",
        "  tensor_0 = torch.zeros(1, device=device)\n",
        "  tensor_1 = torch.ones(1, device=device)\n",
        "\n",
        "  RX = torch.stack([\n",
        "                  torch.stack([tensor_1, tensor_0, tensor_0]),\n",
        "                  torch.stack([tensor_0, torch.cos(roll), -torch.sin(roll)]),\n",
        "                  torch.stack([tensor_0, torch.sin(roll), torch.cos(roll)])]).reshape(3,3)\n",
        "\n",
        "  RY = torch.stack([\n",
        "                  torch.stack([torch.cos(pitch), tensor_0, torch.sin(pitch)]),\n",
        "                  torch.stack([tensor_0, tensor_1, tensor_0]),\n",
        "                  torch.stack([-torch.sin(pitch), tensor_0, torch.cos(pitch)])]).reshape(3,3)\n",
        "\n",
        "  RZ = torch.stack([\n",
        "                  torch.stack([torch.cos(yaw), -torch.sin(yaw), tensor_0]),\n",
        "                  torch.stack([torch.sin(yaw), torch.cos(yaw), tensor_0]),\n",
        "                  torch.stack([tensor_0, tensor_0, tensor_1])]).reshape(3,3)\n",
        "\n",
        "  R = torch.mm(RX, RY)\n",
        "  R = torch.mm(R, RZ)\n",
        "  return R\n",
        "\n",
        "\n",
        "def match_points_pytorch(transformed, ref_torch):\n",
        "  r1, r2 = torch.norm(transformed, dim=0, keepdim=True), torch.norm(ref_torch, dim=0, keepdim=True)  \n",
        "  dist = r2 - 2* torch.mm(transformed.T, ref_torch)  + r1.T\n",
        "  return dist.argmin(dim=1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SGD_ICP_PY/sgd_icp_python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvxX0IpkcoN7"
      },
      "source": [
        "# ICP code from class\n",
        "Excecute this cell to import modules and define functions\n",
        "Here is also the first implementation of sgd_icp in plain Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J2ptDyd9qKE"
      },
      "source": [
        "#\n",
        "#\n",
        "#      0===================================0\n",
        "#      |    TP2 Iterative Closest Point    |\n",
        "#      0===================================0\n",
        "#\n",
        "#-------------------------------------------------------------------\n",
        "#\n",
        "#      Hugues THOMAS - 17/01/2018\n",
        "\n",
        "\n",
        "def best_rigid_transform(data, ref):\n",
        "    '''\n",
        "    Computes the least-squares best-fit transform that maps corresponding points data to ref.\n",
        "    Inputs :\n",
        "        data = (d x N) matrix where \"N\" is the number of points and \"d\" the dimension\n",
        "         ref = (d x N) matrix where \"N\" is the number of points and \"d\" the dimension\n",
        "    Returns :\n",
        "           R = (d x d) rotation matrix\n",
        "           T = (d x 1) translation vector\n",
        "           Such that R * data + T is aligned on ref\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    p = ref.mean(1).reshape(-1,1)\n",
        "    p_prime = data.mean(1).reshape(-1,1)    \n",
        "    U, S, V = np.linalg.svd((data-p_prime) @ (ref-p).T, full_matrices=False)\n",
        "    V = V.T\n",
        "    R = V @ U.T\n",
        "    if np.linalg.det(R)<0:\n",
        "        U[:,-1] *= -1\n",
        "        R = V @ U.T\n",
        "    \n",
        "    T = p - R @ p_prime\n",
        "    return R, T.reshape(-1,1)\n",
        "\n",
        "\n",
        "def icp_point_to_point(data, ref, max_iter, RMS_threshold, show_progress=False):\n",
        "    '''\n",
        "    Iterative closest point algorithm with a point to point strategy.\n",
        "    Inputs :\n",
        "        data = (d x N_data) matrix where \"N_data\" is the number of points and \"d\" the dimension\n",
        "        ref = (d x N_ref) matrix where \"N_ref\" is the number of points and \"d\" the dimension\n",
        "        max_iter = stop condition on the number of iterations\n",
        "        RMS_threshold = stop condition on the distance\n",
        "    Returns :\n",
        "        data_aligned = data aligned on reference cloud\n",
        "        R_list = list of the (d x d) rotation matrices found at each iteration\n",
        "        T_list = list of the (d x 1) translation vectors found at each iteration\n",
        "        neighbors_list = At each iteration, you search the nearest neighbors of each data point in\n",
        "        the ref cloud and this obtain a (1 x N_data) array of indices. This is the list of those\n",
        "        arrays at each iteration\n",
        "           \n",
        "    '''\n",
        "\n",
        "    # Variable for aligned data\n",
        "    data_aligned = np.copy(data)\n",
        "    \n",
        "    # Initiate lists\n",
        "    R_list = []\n",
        "    T_list = []\n",
        "    neighbors_list = []\n",
        "    RMS_list = []\n",
        "    tree = KDTree(ref.T)\n",
        "    for i in range(max_iter):\n",
        "        # Match points\n",
        "        ind = tree.query(data_aligned.T, return_distance=False).squeeze()\n",
        "        #ICP\n",
        "        R, T = best_rigid_transform(data, ref[:,ind])\n",
        "        data_aligned = R @ data + T\n",
        "        neighbors_list.append(ind)        \n",
        "        R_list.append(R)\n",
        "        T_list.append(T)\n",
        "        rms = RMS(data_aligned, ref[:,ind])\n",
        "        RMS_list.append(rms)\n",
        "        if show_progress: print('{:.3f}'.format(rms))\n",
        "        if rms < RMS_threshold: break\n",
        "    return data_aligned, R_list, T_list, neighbors_list, RMS_list\n",
        "\n",
        "def icp_point_to_point_fast(data, ref, max_iter, RMS_threshold, sampling_limit, resample=False, show_progress=False):\n",
        "    '''\n",
        "    Iterative closest point algorithm with a point to point strategy.\n",
        "    Inputs :\n",
        "        data = (d x N_data) matrix where \"N_data\" is the number of points and \"d\" the dimension\n",
        "        ref = (d x N_ref) matrix where \"N_ref\" is the number of points and \"d\" the dimension\n",
        "        max_iter = stop condition on the number of iterations\n",
        "        RMS_threshold = stop condition on the distance\n",
        "    Returns :\n",
        "        data_aligned = data aligned on reference cloud\n",
        "        R_list = list of the (d x d) rotation matrices found at each iteration\n",
        "        T_list = list of the (d x 1) translation vectors found at each iteration\n",
        "        neighbors_list = At each iteration, you search the nearest neighbors of each data point in\n",
        "        the ref cloud and this obtain a (1 x N_data) array of indices. This is the list of those\n",
        "        arrays at each iteration\n",
        "           \n",
        "    '''\n",
        "\n",
        "    # Variable for aligned data\n",
        "    data_aligned = np.copy(data)\n",
        "    \n",
        "    # Initiate lists\n",
        "    R_list = []\n",
        "    T_list = []\n",
        "    neighbors_list = []\n",
        "    RMS_list = []\n",
        "    tree = KDTree(ref.T)\n",
        "    data_sample_ind = np.random.choice(data.shape[1], size= min(data.shape[1],sampling_limit), replace=False)\n",
        "    for i in range(max_iter):\n",
        "        if resample:\n",
        "            # Sample\n",
        "            data_sample_ind = np.random.choice(data.shape[1], size= min(data.shape[1],sampling_limit), replace=False)\n",
        "        \n",
        "    \n",
        "        # Match points\n",
        "        ind = tree.query(data_aligned[:,data_sample_ind].T, return_distance=False).squeeze()\n",
        "        #ICP\n",
        "        R, T = best_rigid_transform(data[:,data_sample_ind], ref[:,ind])\n",
        "        \n",
        "        data_aligned = R @ data + T\n",
        "        \n",
        "        neighbors_list.append((data_sample_ind,ind))        \n",
        "        R_list.append(R)\n",
        "        T_list.append(T)\n",
        "        ind = tree.query(data_aligned.T, return_distance=False).squeeze()\n",
        "        rms = RMS(data_aligned, ref[:,ind])\n",
        "        RMS_list.append(rms)\n",
        "        if show_progress: print('{:.3f}'.format(rms))\n",
        "        if rms < RMS_threshold: break\n",
        "    \n",
        "    return data_aligned, R_list, T_list, neighbors_list, RMS_list\n",
        "\n",
        "\n",
        "def sgd_icp(source, ref, epochs, RMS_threshold, batch_size, dmax,\n",
        "            show_progress=False, eval_every = 1, theta_init=None,\n",
        "            alpha = lambda i: 0.001, beta1=0.9, beta2=0.999, eps=1e-6,\n",
        "            resample=False):\n",
        "    '''\n",
        "    Iterative closest point algorithm using sgd\n",
        "    Inputs :\n",
        "        source = (d x N_source) matrix where \"N_source\" is the number of points and \"d\" the dimension\n",
        "        ref = (d x N_ref) matrix where \"N_ref\" is the number of points and \"d\" the dimension\n",
        "        epochs = stop condition on the number of iterations\n",
        "        RMS_threshold = stop condition on the distance\n",
        "    Returns :\n",
        "        data_aligned = data aligned on reference cloud\n",
        "        R_list = list of the (d x d) rotation matrices found at each iteration\n",
        "        T_list = list of the (d x 1) translation vectors found at each iteration\n",
        "        neighbors_list = At each iteration, you search the nearest neighbors of each data point in\n",
        "        the ref cloud and this obtain a (1 x N_data) array of indices. This is the list of those\n",
        "        arrays at each iteration\n",
        "           \n",
        "    '''\n",
        "    # Initiate lists\n",
        "    R_list, T_list, norms_list, RMS_list, rms = [], [], [], [], 0     \n",
        "    tree, N = KDTree(ref.T), source.shape[1]    \n",
        "    indices, total_time, last_epoch_time = np.arange(N), 0, 0   \n",
        "    beta1t, beta2t = beta1, beta2\n",
        "\n",
        "    if theta_init is None:\n",
        "      theta = np.zeros(6)\n",
        "    else:\n",
        "      theta = theta_init.copy()\n",
        "\n",
        "    \n",
        "    mR, vR = np.zeros_like(theta), np.zeros_like(theta)\n",
        "    mhatR, vhatR = np.zeros_like(theta), np.zeros_like(theta)\n",
        "\n",
        "    for i in tqdm(range(epochs)):\n",
        "      start = time.process_time()\n",
        "      \n",
        "      # Shuffle the indices\n",
        "      np.random.shuffle(indices)\n",
        "      \n",
        "      for b in range(N//batch_size):\n",
        "        # print(f'\\tBatch {b} out of {N//batch_size}')\n",
        "        if resample:\n",
        "          batch_ind = np.random.choice(N, batch_size, replace=False)\n",
        "        else:\n",
        "          batch_ind = indices[batch_size*b:batch_size*(b+1)]\n",
        "    \n",
        "        # Match points        \n",
        "        transformed = apply_transform_from_theta(source[:,batch_ind], theta)\n",
        "        ind = match_points(transformed, tree)\n",
        "                \n",
        "        #ICP in class\n",
        "        # R, T = best_rigid_transform(source[:,batch_ind], ref[:,ind])\n",
        "        \n",
        "        #SGD_ICP\n",
        "        gradR = gradient_wrt_theta(source[:,batch_ind], ref[:,ind], theta)\n",
        "        norms_list.append(np.linalg.norm(gradR))\n",
        "        \n",
        "        mR, vR = beta1*mR + (1-beta1)*gradR, beta2*vR + (1-beta2)*gradR*gradR\n",
        "        mhatR, vhatR = mR/(1-beta1t), vR/(1-beta2t)\n",
        "        \n",
        "        beta1t *= beta1\n",
        "        beta2t *= beta2\n",
        "        if beta2 > 0:          \n",
        "          sgdR = mhatR / (np.sqrt(vhatR)+eps)\n",
        "        else:          \n",
        "          sgdR = mhatR\n",
        "        \n",
        "        theta = theta - alpha(i)*sgdR        \n",
        "                    \n",
        "      R, T = theta_to_tranformation(theta)\n",
        "      R_list.append(R.copy())\n",
        "      T_list.append(T.copy())\n",
        "      if (i+1)%eval_every==0:        \n",
        "        # Compute RMS        \n",
        "        transformed = apply_transform(source, R, T)\n",
        "        ind = tree.query(transformed.T, return_distance=False).squeeze()\n",
        "        rms = RMS(transformed, ref[:,ind])\n",
        "        RMS_list.append(rms)\n",
        "        if show_progress:\n",
        "          print(f'Epoch {i:02d}:\\ntotal time: {total_time:.1f}s\\tlast epoch: {last_epoch_time:.1f}s\\trms: {rms:.3f}')\n",
        "        \n",
        "        if rms < RMS_threshold: break\n",
        "      last_epoch_time = time.process_time() - start\n",
        "      total_time += last_epoch_time    \n",
        "    transformed = apply_transform(source, R, T)\n",
        "    return transformed, R_list, T_list, norms_list, RMS_list\n",
        "\n",
        "def match_points(transformed, tree, dmax = np.inf):\n",
        "  dist, ind = tree.query(transformed.T, return_distance=True)\n",
        "  dist, ind  = dist.squeeze(), ind.squeeze()\n",
        "  return ind[(dist<dmax)]\n",
        "\n",
        "def RMS(c1, c2):\n",
        "    return np.sqrt(np.mean(np.sum(np.power(c1 - c2, 2), axis=0)))\n",
        "\n",
        "\n",
        "def plain_array(arr, fields):\n",
        "  return np.array(np.vstack([arr[f] for f in fields]))\n",
        "\n",
        "def read_ply_file(path, fields):\n",
        "  ply_cloud = read_ply(path)  \n",
        "  return plain_array(ply_cloud, fields)\n",
        "\n",
        "def pcd_to_numpy(pc):\n",
        "  arr = np.zeros((3,len(pc.pc_data)))\n",
        "  arr[0,:] = pc.pc_data['x']\n",
        "  arr[1,:] = pc.pc_data['y']\n",
        "  arr[2,:] = pc.pc_data['z']\n",
        "  return arr\n",
        " "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iGczPLFI5R4"
      },
      "source": [
        "# Test the authors code with the Bremen cloud and the Bunny cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MamlhJFkDVc3"
      },
      "source": [
        "## **Test authors implementation on the bunny cloud**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbtJKYb1_s6L"
      },
      "source": [
        "source = read_ply_file('/content/SGD_ICP_PY/data/bunny_original.ply',['x','y','z'])\n",
        "ref = read_ply_file('/content/SGD_ICP_PY/data/bunny_perturbed.ply',['x','y','z'])\n",
        "\n",
        "plot_clouds(source, ref, ref)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2nV7y2h79cm"
      },
      "source": [
        "'''\n",
        "Transforms the bunny in ply format to pcd format to be able to use it with the authors code\n",
        "'''\n",
        "fields = ['x','y','z']\n",
        "dt = np.dtype([(f, 'float32') for f in fields])\n",
        "for p in ['bunny_original', 'bunny_perturbed']:\n",
        "  path_input = os.path.join('/content/SGD_ICP_PY/data', p + '.ply')\n",
        "  source = read_ply_file(path_input, ['x','y','z'])\n",
        "  res = np.array(source.T, dtype=dt)\n",
        "  # res.dtype = dt\n",
        "  path_out = os.path.join('/content/SGD_ICP_PY/data', p + '.pcd')\n",
        "  pc = pcd.PointCloud.from_array(res)\n",
        "  pc.save_pcd(path_out)\n",
        "  pc = pcd.point_cloud_from_path(path_out)\n",
        "  pc.pc_data['x'] = source[0,:]\n",
        "  pc.pc_data['y'] = source[1,:]\n",
        "  pc.pc_data['z'] = source[2,:]\n",
        "  pc.save_pcd(path_out)\n"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCHpIo8BX_kB",
        "outputId": "2e53e159-9181-4f86-dfc9-72ca7343953f"
      },
      "source": [
        "input = '/content/SGD_ICP_PY/data/bunny_original.pcd'\n",
        "source = pcd_to_numpy(pcd.point_cloud_from_path(input))\n",
        "plot_clouds(source,source, source)"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03334056, -0.04052266, -0.05847169, ..., -0.06888419,\n",
              "        -0.06909736, -0.06904293],\n",
              "       [ 0.03831694,  0.03972047, -0.00213994, ...,  0.0510544 ,\n",
              "         0.05398326,  0.05560543],\n",
              "       [ 0.05281038,  0.05431097,  0.06881585, ..., -0.03270832,\n",
              "        -0.03232504, -0.0321591 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Goklr_EEHDfb"
      },
      "source": [
        "# Compare our transformation to the authors transformation\n",
        "input = '/content/SGD_ICP_PY/data/bunny_original.pcd'\n",
        "output = '/content/SGD_ICP_PY/data/bunny_authors.pcd'\n",
        "source = pcd_to_numpy(pcd.point_cloud_from_path(input))\n",
        "\n",
        "\n",
        "%cd /content/sgd_icp/bin\n",
        "x, y, z, roll, pitch, yaw = 0.01,0.03,0,0,0,np.pi/6\n",
        "!./transform_cloud --input $input --output $output --pose $x $y $z $roll $pitch $yaw\n",
        "\n",
        "ref = pcd_to_numpy(pcd.point_cloud_from_path(output))\n",
        "\n",
        "R, T = roll_pitch_yaw(roll, pitch, yaw), np.array([x,y,z])\n",
        "test = apply_transform(source, R, T)\n",
        "\n",
        "plot_clouds(source, ref, test, drop_rate=0.95, size = 1, careful=False)\n",
        "# ref and test should be the same, meaning authors tranformations and ours coincide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGaX9X9Y7UEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ccfbb88-d5cd-4381-a194-187465808f22"
      },
      "source": [
        "if True: # This can take time \n",
        "  # Prepare config file\n",
        "  config_def = '/content/sgd_icp/config.json'\n",
        "  with open(config_def) as f:\n",
        "    config_dict = json.load(f)\n",
        "  config_dict['normalize-cloud'] = True\n",
        "  initial_guess = {'x': 0.0, 'y': 0.0, 'z': 0.0, 'roll': 0.2, 'pitch': 0.0, 'yaw': 0.0}\n",
        "  config_dict['initial-guess'] = initial_guess\n",
        "\n",
        "\n",
        "  source = '/content/SGD_ICP_PY/data/bunny_original.pcd'\n",
        "  ref = '/content/SGD_ICP_PY/data/bunny_perturbed.pcd'\n",
        "  config_path = '/content/sgd_icp/my_config.json'\n",
        "  with open(config_path, 'w') as f:\n",
        "    json.dump(config_dict, f)\n",
        "  # Test here. Uses PCD format for the clouds. Config file example is given in repository: JSON file with parameters\n",
        "  # align_pcd <source_cloud> <target_cloud> <cofig_file>\n",
        "\n",
        "  %cd /content/sgd_icp/bin\n",
        "  \n",
        "  !./align_pcd $source $ref $config_path"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sgd_icp/bin\n",
            "Convergence achieved\n",
            "Iterations: 41 converged: 1\n",
            "ICP Duration: 17 ms\n",
            "RMSE: 0.0816544\n",
            "Transformation_matrix:\n",
            "   0.988567   -0.147452   0.0315242  0.00947917\n",
            "   0.150779    0.968504   -0.198158  0.00394455\n",
            "-0.00131248    0.200645    0.979663  -0.0187244\n",
            "          0           0           0           1\n",
            "[x, y, z, roll, pitch, yaw] = [0.00947917,0.00394455,-0.0187244,0.202017,0.00131248,0.151356]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_D5A_3V5ndf"
      },
      "source": [
        "%cd /content/SGD_ICP_PY\n",
        "# This values are the output of the sgd_icp method\n",
        "x, y, z, roll, pitch, yaw = 0.00947917,0.00394455,-0.0187244,0.202017,0.00131248,0.151356\n",
        "# x, y, z, roll, pitch, yaw = 0.00892445,0.00996263,0.0126189,0.0934348,0.0311362,0.0600543\n",
        "R, T = roll_pitch_yaw(roll, pitch, yaw), np.array([x,y,z])\n",
        "\n",
        "source = read_ply_file('/content/SGD_ICP_PY/data/bunny_original.ply',['x','y','z'])\n",
        "test = source.copy()\n",
        "ref = read_ply_file('/content/SGD_ICP_PY/data/bunny_perturbed.ply',['x','y','z'])\n",
        "\n",
        "test = apply_transform(source, R, T)\n",
        "\n",
        "plot_clouds(source, ref, test, drop_rate=0.95, careful=False)\n",
        "# files.download('./data/pcd_bremen/my_bremen_sgd_icp.pcd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdICxac5DZnz"
      },
      "source": [
        "##**Test it on the Bremen cloud**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0e0fp_XvGOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab11a56-0b8d-49ff-ecae-fbec10df9fb1"
      },
      "source": [
        "'''\n",
        "Build an unified cloud using different parts from the Bremen dataset\n",
        "'''\n",
        "%cd /content/SGD_ICP_PY\n",
        "parts = [0, 1]\n",
        "path_out = '/content/SGD_ICP_PY/data/pcd_bremen/my_bremen.pcd'\n",
        "\n",
        "paths_in = ['/content/SGD_ICP_PY/data/pcd_bremen/pcd_bremen/scan_0{0:02d}.pcd'.format(i) for i in parts]\n",
        "save_whole_cloud_pcd(paths_in, path_out)\n",
        "# files.download(path_out) # If you want to download the cloud to your machine\n",
        "\n",
        "\n",
        "# Create a copy but rotated and translated to try to align them\n",
        "x, y, z, roll, pitch, yaw = 0.1,0.5,0,0,0,np.pi/6\n",
        "R, T = roll_pitch_yaw(roll, pitch, yaw), np.array([x,y,z])\n",
        "pc = pcd.point_cloud_from_path(path_out)\n",
        "pc = apply_transform(pc, R, T)\n",
        "\n",
        "path_out_mod = '/content/SGD_ICP_PY/data/pcd_bremen/my_bremen_mod.pcd'\n",
        "pc.save_pcd(path_out_mod)\n",
        "# files.download(path_out_mod) # If you want to download the cloud to your machine"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SGD_ICP_PY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGNiXJd7Dcdj",
        "outputId": "d74962d0-aab9-47a7-88ea-c3db300cffd2"
      },
      "source": [
        "'''\n",
        "It seems like the cloud is too big. \n",
        "For some reason the functions gets stuck at the end\n",
        "'''\n",
        "if True: # This can take time \n",
        "  # Prepare config file\n",
        "  config_def = '/content/sgd_icp/config.json'\n",
        "  with open(config_def) as f:\n",
        "    config_dict = json.load(f)\n",
        "  config_dict['normalize-cloud'] = False\n",
        "  initial_guess = {'x': 0.1, 'y': 0.3, 'z': 0.0, 'roll': 0.0, 'pitch': 0.0, 'yaw': 0.3}\n",
        "  config_dict['initial-guess'] = initial_guess\n",
        "\n",
        "\n",
        "  source = '/content/SGD_ICP_PY/data/pcd_bremen/my_bremen.pcd'\n",
        "  ref = '/content/SGD_ICP_PY/data/pcd_bremen/my_bremen_mod.pcd'\n",
        "  \n",
        "  config_path = '/content/sgd_icp/my_config.json'\n",
        "  with open(config_path, 'w') as f:\n",
        "    json.dump(config_dict, f)\n",
        "  # Test here. Uses PCD format for the clouds. Config file example is given in repository: JSON file with parameters\n",
        "  # align_pcd <source_cloud> <target_cloud> <cofig_file>\n",
        "\n",
        "  %cd /content/sgd_icp/bin\n",
        "  \n",
        "  !./align_pcd $source $ref $config_path"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Options:\n",
            "  --help                Show the help message\n",
            "  --source arg          Source point cloud\n",
            "  --target arg          Target point cloud\n",
            "  --config arg          Configuration\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESGmTcTzEXUT"
      },
      "source": [
        "%cd /content/SGD_ICP_PY\n",
        "# This values are the output of the sgd_icp method\n",
        "x, y, z, roll, pitch, yaw = 0.00426878,0.001404,0.0115587,0.197809,0.0598428,0.111875\n",
        "R, T = roll_pitch_yaw(roll, pitch, yaw), np.array([x,y,z])\n",
        "\n",
        "source = pcd_to_numpy(pcd.point_cloud_from_path('/content/SGD_ICP_PY/data/pcd_bremen/my_bremen.pcd'))\n",
        "ref = pcd_to_numpy(pcd.point_cloud_from_path('/content/SGD_ICP_PY/data/pcd_bremen/my_bremen_mod.pcd'))\n",
        "\n",
        "test = apply_transform(source, R, T)\n",
        "\n",
        "plot_clouds(source, ref, test, drop_rate=0.999, careful=False, size = 0.1)\n",
        "# files.download('./data/pcd_bremen/my_bremen_sgd_icp.pcd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7qh7d2LJ3EH"
      },
      "source": [
        "# Test the ICP code from class and sgd_icp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-HE3CGTcnlG"
      },
      "source": [
        "path = '/content/SGD_ICP_PY/data/bunny_original.ply'\n",
        "source = normalize(read_ply_file(path, ['x','y','z']))\n",
        "theta_orig = np.array([-1.0,-1.0,0.0, 0, np.pi/3, np.pi/3])\n",
        "ref_orig = apply_transform_from_theta(source, theta_orig)\n",
        "dif_centers = source.mean(axis=1) - ref_orig.mean(axis=1)\n",
        "ref_mean = ref_orig.mean(axis=1).reshape(-1,1)\n",
        "ref = ref_orig - ref_mean"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB9683dOFwLS"
      },
      "source": [
        "'''\n",
        "Both clouds are in correspondence, so the naive ICP will work.\n",
        "This functions assumes the clouds are already matched\n",
        "'''\n",
        "icp_cloud, R_list, T_list, _, RMS_list = icp_point_to_point(source, ref, 50, 1e-4, show_progress=False)\n",
        "plot_clouds(source, ref_orig, icp_cloud+ref_mean, drop_rate=0.97 , careful=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mq0rwICuUZi"
      },
      "source": [
        "'''\n",
        "Now lets shuffle the reference and try again\n",
        "'''\n",
        "np.random.shuffle(ref.T)\n",
        "icp_cloud_shuffle, R_list_shuffle, T_list_shuffle, _, RMS_list_shuffle = \\\n",
        "  icp_point_to_point(source, ref, 50, 1e-4, show_progress=False)\n",
        "plot_clouds(source, ref_orig, icp_cloud_shuffle+ref_mean, drop_rate=0.97 , careful=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOna08O2ZjuA"
      },
      "source": [
        "'''\n",
        "Let's try SGD\n",
        "'''\n",
        "init, warm_up, decay = 0.1, 15, 0.999\n",
        "epochs = 50\n",
        "warm_up_decay = lambda i: i*(init/warm_up) if i < warm_up  else init*decay**(int((i-warm_up+1)))\n",
        "# Add noise to the real theta for the starting transformation\n",
        "theta_init = add_noise(theta_orig,0,0.2)\n",
        "\n",
        "icp_cloud_sgd, R_list_sgd, T_list_sgd, norms_list, RMS_list_sgd = sgd_icp(source, ref, epochs, 1e-4,\n",
        "            batch_size=10000, dmax=1,\n",
        "            show_progress=False, eval_every = 15, theta_init=theta_init,\n",
        "            alpha = warm_up_decay, beta1=0.9, beta2=0.999, eps=1e-6,\n",
        "            resample=False)\n",
        "plot_clouds(source, ref_orig, icp_cloud_shuffle+ref_mean, drop_rate=0.9 , careful=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyBCSStLndlH"
      },
      "source": [
        "**Bremen cloud**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1s4b_P4nf3v"
      },
      "source": [
        "path = '/content/SGD_ICP_PY/data/pcd_bremen/my_bremen.pcd'\n",
        "source = normalize(pcd_to_numpy(pcd.point_cloud_from_path(path)))\n",
        "theta_orig = np.array([-1.0,-1.0,0.0, np.pi/2, np.pi/3, np.pi/3])\n",
        "ref_orig = apply_transform_from_theta(source, theta_orig)\n",
        "dif_centers = source.mean(axis=1) - ref_orig.mean(axis=1)\n",
        "ref_mean = ref_orig.mean(axis=1).reshape(-1,1)\n",
        "ref = ref_orig - ref_mean"
      ],
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "53ad59ae73db4beab5e0a414bdea08b9",
            "c97185726e52473698fcd3dfa95f10f0",
            "d0c20aef67914a92866efee3ae28c3c0",
            "917b0f73081b4e73b838835648d1c1bb",
            "2c476c14628d414bac9504a0b92e4531",
            "957dac19e8584c6aa38d61bab6884ae1",
            "a47e84eb56ae4f2fae697618dd30520f",
            "fd33650d6a6a46aebec8396a7617e6e0"
          ]
        },
        "id": "ONppWR_knvwq",
        "outputId": "adf1d97c-121e-4b94-afb2-31793b751736"
      },
      "source": [
        "'''\n",
        "Let's try SGD\n",
        "'''\n",
        "init, warm_up, decay = 0.01, 10, 0.999\n",
        "epochs = 50\n",
        "warm_up_decay = lambda i: i*(init/warm_up) if i < warm_up  else init*decay**(int((i-warm_up+1)))\n",
        "# Add noise to the real theta for the starting transformation\n",
        "theta_init = add_noise(theta_orig,0,0.2)\n",
        "\n",
        "icp_cloud_sgd, R_list_sgd, T_list_sgd, norms_list, RMS_list_sgd = sgd_icp(source, ref, epochs, 1e-4,\n",
        "            batch_size=10000, dmax=1,\n",
        "            show_progress=False, eval_every = 1, theta_init=theta_init,\n",
        "            alpha = warm_up_decay, beta1=0.9, beta2=0.999, eps=1e-6,\n",
        "            resample=False)\n",
        "\n",
        "# plot_clouds(source, ref_orig, icp_cloud_shuffle+ref_mean, drop_rate=0.9 , careful=True)\n",
        "plt.plot(RMS_list_sgd)"
      ],
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53ad59ae73db4beab5e0a414bdea08b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9d5d3cf7d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 430
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "i0iGe0AIqRW3",
        "outputId": "8b55ce3b-dfc5-48ec-c62b-0a5eebb0c632"
      },
      "source": [
        "write_ply('/content/SGD_ICP_PY/data/pcd_bremen/my_bremen_sgd_icp.ply', icp_cloud_sgd.T, ['x', 'y', 'z'])\n",
        "files.download('/content/SGD_ICP_PY/data/pcd_bremen/my_bremen_sgd_icp.ply')"
      ],
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e2f864d6-8c7c-415c-85a2-51a5331cf9af\", \"my_bremen_sgd_icp.ply\", 67342423)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osHeYQYWFqpp"
      },
      "source": [
        "# Using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tjnXtqrBTU3"
      },
      "source": [
        "'''\n",
        "ICP using SGD, implemented on PyTorch\n",
        "'''\n",
        "def run_icp_pytorch(path_input, theta_orig, noise_level=0.1, epochs=50,\n",
        "                    batch_size=128, resample=False, matching_technique='torch',\n",
        "                    plot=False, eval_every=1):\n",
        "  if '.ply' in path_input:\n",
        "    source = normalize(read_ply_file(path_input, ['x','y','z']), and_center=True)\n",
        "  elif '.pcd' in path_input:\n",
        "    source = normalize(pcd_to_numpy(pcd.point_cloud_from_path(path_input)), and_center=True)\n",
        "  else:    \n",
        "    raise Exception('Invalid input format. Only accepting ply and pcd') \n",
        "\n",
        "  ref_orig = apply_transform_from_theta(source, theta_orig)\n",
        "  dif_centers = source.mean(axis=1) - ref_orig.mean(axis=1)\n",
        "  ref_mean = ref_orig.mean(axis=1).reshape(-1,1)\n",
        "  ref = ref_orig - ref_mean\n",
        "\n",
        "  source_torch = torch.tensor(source, dtype=torch.float, device=device)\n",
        "  ref_torch = torch.tensor(ref, dtype=torch.float, device=device)\n",
        "\n",
        "  theta_noise = add_noise(theta_orig, 0, noise_level)\n",
        "  roll_opt = torch.tensor([float(theta_noise[3])], requires_grad=True, device=device)\n",
        "  pitch_opt = torch.tensor([float(theta_noise[4])], requires_grad=True, device=device)\n",
        "  yaw_opt = torch.tensor([float(theta_noise[5])], requires_grad=True, device=device)\n",
        "\n",
        "  T_opt = torch.zeros((3,1), requires_grad=True, device=device)\n",
        "\n",
        "  angles_optimizer = torch.optim.Adam(params = [roll_opt, pitch_opt, yaw_opt, T_opt])\n",
        "  # T_optimizer = torch.optim.Adam(params = [T_opt])\n",
        "  tree, N = KDTree(ref.T), source.shape[1]\n",
        "  indices = np.arange(N)\n",
        "  RMS_list = []\n",
        "  for i in tqdm(range(epochs)):\n",
        "    \n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    for b in range(N//batch_size):    \n",
        "      if resample:\n",
        "        batch_ind = np.random.choice(N, batch_size, replace=False)\n",
        "      else:\n",
        "        batch_ind = indices[batch_size*b:batch_size*(b+1)]\n",
        "\n",
        "      R_opt = rotation_matrix(roll_opt, pitch_opt, yaw_opt, device)\n",
        "\n",
        "      # Match points\n",
        "      if matching_technique == 'identity':\n",
        "        ind = batch_ind.copy()\n",
        "      else:      \n",
        "        transformed = (torch.mm(R_opt, source_torch[:,batch_ind])) + T_opt\n",
        "        if matching_technique == 'torch':\n",
        "          ind = match_points_pytorch(transformed, ref_torch)\n",
        "        elif matching_technique == 'kdtree': \n",
        "          ind = match_points(transformed.to('cpu').detach().numpy(), tree)\n",
        "          \n",
        "      angles_optimizer.zero_grad()    \n",
        "      loss = torch.norm((torch.mm(R_opt, source_torch[:,batch_ind]) + T_opt) - ref_torch[:,ind], p=2).mean()\n",
        "      loss.backward()\n",
        "      angles_optimizer.step()\n",
        "    \n",
        "    if (i+1)%eval_every==0:\n",
        "      with torch.no_grad():\n",
        "        \n",
        "        R_opt = rotation_matrix(roll_opt, pitch_opt, yaw_opt, device)\n",
        "        # Match points\n",
        "        if matching_technique == 'identity':\n",
        "          ind = np.arange(N)\n",
        "        else:      \n",
        "          transformed = (torch.mm(R_opt, source_torch)) + T_opt\n",
        "          if matching_technique == 'torch':\n",
        "            ind = match_points_pytorch(transformed, ref_torch)\n",
        "          elif matching_technique == 'kdtree': \n",
        "            ind = match_points(transformed.to('cpu').detach().numpy(), tree)\n",
        "        \n",
        "        loss = torch.norm((torch.mm(R_opt, source_torch) + T_opt) - ref_torch[:,ind], p=2).mean()\n",
        "        RMS_list.append(loss.item())\n",
        "\n",
        "\n",
        "  if plot:\n",
        "    R_opt = rotation_matrix(roll_opt, pitch_opt, yaw_opt, device)\n",
        "    test = torch.mm(R_opt, source_torch) + T_opt\n",
        "    plot_clouds(source, ref_orig, test.to('cpu').detach().numpy() + ref_mean, drop_rate = 0.9, careful=False)\n",
        "  return RMS_list, roll_opt, pitch_opt, yaw_opt, T_opt\n",
        "\n",
        "\n",
        "def run_icp_pytorch_two_clouds(path_input_source, path_input_ref, theta_init=None, epochs=50,\n",
        "                    batch_size=128, resample=False, matching_technique='torch',\n",
        "                    plot=False, eval_every=1):\n",
        "  if '.ply' in path_input_source:\n",
        "    source = normalize(read_ply_file(path_input_source, ['x','y','z']), and_center=True)\n",
        "  elif '.pcd' in path_input_source:\n",
        "    source = normalize(pcd_to_numpy(pcd.point_cloud_from_path(path_input_source)), and_center=True)\n",
        "  else:    \n",
        "    raise Exception('Invalid input format. Only accepting ply and pcd') \n",
        "\n",
        "\n",
        "  if '.ply' in path_input_ref:\n",
        "    ref_orig = normalize(read_ply_file(path_input_ref, ['x','y','z']), and_center=True)\n",
        "  elif '.pcd' in path_input_ref:\n",
        "    ref_orig = normalize(pcd_to_numpy(pcd.point_cloud_from_path(path_input_ref)), and_center=True)\n",
        "  else:    \n",
        "    raise Exception('Invalid input format. Only accepting ply and pcd') \n",
        "\n",
        "  dif_centers = source.mean(axis=1) - ref_orig.mean(axis=1)\n",
        "  ref_mean = ref_orig.mean(axis=1).reshape(-1,1)\n",
        "  ref = ref_orig - ref_mean\n",
        "\n",
        "  source_torch = torch.tensor(source, dtype=torch.float, device=device)\n",
        "  ref_torch = torch.tensor(ref, dtype=torch.float, device=device)\n",
        "\n",
        "  if theta_init is None:\n",
        "    theta_init=np.random.randn(6)\n",
        "  roll_opt = torch.tensor([float(theta_init[3])], requires_grad=True, device=device)\n",
        "  pitch_opt = torch.tensor([float(theta_init[4])], requires_grad=True, device=device)\n",
        "  yaw_opt = torch.tensor([float(theta_init[5])], requires_grad=True, device=device)\n",
        "\n",
        "  T_opt = torch.zeros((3,1), requires_grad=True, device=device)\n",
        "\n",
        "  angles_optimizer = torch.optim.Adam(params = [roll_opt, pitch_opt, yaw_opt, T_opt])\n",
        "  # T_optimizer = torch.optim.Adam(params = [T_opt])\n",
        "  tree, N = KDTree(ref.T), source.shape[1]\n",
        "  indices = np.arange(N)\n",
        "  RMS_list = []\n",
        "  for i in tqdm(range(epochs)):\n",
        "    \n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    for b in range(N//batch_size):    \n",
        "      if resample:\n",
        "        batch_ind = np.random.choice(N, batch_size, replace=False)\n",
        "      else:\n",
        "        batch_ind = indices[batch_size*b:batch_size*(b+1)]\n",
        "\n",
        "      R_opt = rotation_matrix(roll_opt, pitch_opt, yaw_opt, device)\n",
        "\n",
        "      # Match points\n",
        "      if matching_technique == 'identity':\n",
        "        ind = batch_ind.copy()\n",
        "      else:      \n",
        "        transformed = (torch.mm(R_opt, source_torch[:,batch_ind])) + T_opt\n",
        "        if matching_technique == 'torch':\n",
        "          ind = match_points_pytorch(transformed, ref_torch)\n",
        "        elif matching_technique == 'kdtree': \n",
        "          ind = match_points(transformed.to('cpu').detach().numpy(), tree)\n",
        "          \n",
        "      angles_optimizer.zero_grad()    \n",
        "      loss = torch.norm((torch.mm(R_opt, source_torch[:,batch_ind]) + T_opt) - ref_torch[:,ind], p=2).mean()\n",
        "      loss.backward()\n",
        "      angles_optimizer.step()\n",
        "    \n",
        "    if (i+1)%eval_every==0:\n",
        "      with torch.no_grad():\n",
        "        \n",
        "        R_opt = rotation_matrix(roll_opt, pitch_opt, yaw_opt, device)\n",
        "        # Match points\n",
        "        if matching_technique == 'identity':\n",
        "          ind = np.arange(N)\n",
        "        else:      \n",
        "          transformed = (torch.mm(R_opt, source_torch)) + T_opt\n",
        "          if matching_technique == 'torch':\n",
        "            ind = match_points_pytorch(transformed, ref_torch)\n",
        "          elif matching_technique == 'kdtree': \n",
        "            ind = match_points(transformed.to('cpu').detach().numpy(), tree)\n",
        "        \n",
        "        loss = torch.norm((torch.mm(R_opt, source_torch) + T_opt) - ref_torch[:,ind], p=2).mean()\n",
        "        RMS_list.append(loss.item())\n",
        "\n",
        "\n",
        "  if plot:\n",
        "    R_opt = rotation_matrix(roll_opt, pitch_opt, yaw_opt, device)\n",
        "    test = torch.mm(R_opt, source_torch) + T_opt\n",
        "    plot_clouds(source, ref_orig, test.to('cpu').detach().numpy() + ref_mean, drop_rate = 0.9, careful=False)\n",
        "  return RMS_list, roll_opt, pitch_opt, yaw_opt, T_opt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqp9o_aKw2Dq"
      },
      "source": [
        "'''\n",
        "Define all parameters and run the function to align a cloud and a tranformed version\n",
        "'''\n",
        "path_input = '/content/SGD_ICP_PY/data/bunny_original.ply'\n",
        "\n",
        "# Define the transform (x,y,z,roll,pitch,yaw)\n",
        "theta_orig = np.array([-1.0,-1.0,+1.0, np.pi/2, np.pi/6*5, np.pi/3])\n",
        "\n",
        "# Noise to add to the groud truth parameters for the initial guess\n",
        "noise_level = 5\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 1500\n",
        "\n",
        "# Consume the whole cloud before reshuffling, or resample at every batch step\n",
        "resample = False\n",
        "\n",
        "# Matching technique\n",
        "# Options are\n",
        "#   'identity': when matching is known\n",
        "#   'kdtree': Use sklearn KDTree built on the ref cloud\n",
        "#   'torch': Use matrix torch multiplication to compute distances\n",
        "matching_technique = 'identity' \n",
        "\n",
        "# Plot clouds at the end to see where the aligned cloud is w.r.t source and ref\n",
        "plot = True\n",
        "\n",
        "# Frequency to compute total RMS\n",
        "eval_every = 5\n",
        "\n",
        "RMS_list, roll_opt, pitch_opt, yaw_opt, T_opt = run_icp_pytorch(path_input, theta_orig, noise_level, epochs,\n",
        "                    batch_size, resample, matching_technique,\n",
        "                    plot)\n",
        "\n",
        "plt.plot(RMS_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLsfPvqTa6jr"
      },
      "source": [
        "## Try it on the Bremen cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Pb_Mmga9dl"
      },
      "source": [
        "'''\n",
        "Define all parameters here\n",
        "Then execute the next cell\n",
        "'''\n",
        "path_input = '/content/SGD_ICP_PY/data/pcd_bremen/my_bremen.pcd'\n",
        "\n",
        "# Define the transform (x,y,z,roll,pitch,yaw)\n",
        "theta_orig = np.array([-1.0,-5.0,0.0, np.pi/2, np.pi/6, np.pi/3])\n",
        "\n",
        "# Noise to add to the groud truth parameters for the initial guess\n",
        "noise_level = 1\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 5000\n",
        "\n",
        "# Consume the whole cloud before reshuffling, or resample at every batch step\n",
        "resample = False\n",
        "\n",
        "# Matching technique\n",
        "# Options are\n",
        "#   'identity': when matching is known\n",
        "#   'kdtree': Use sklearn KDTree built on the ref cloud\n",
        "#   'torch': Use matrix torch multiplication to compute distances\n",
        "matching_technique = 'identity' \n",
        "\n",
        "# Plot clouds at the end to see where the aligned cloud is w.r.t source and ref\n",
        "plot = False\n",
        "\n",
        "# Frequency to compute total RMS\n",
        "eval_every = 5\n",
        "\n",
        "RMS_list, roll_opt, pitch_opt, yaw_opt, T_opt = run_icp_pytorch(path_input, theta_orig, noise_level, epochs,\n",
        "                    batch_size, resample, matching_technique,\n",
        "                    plot)\n",
        "\n",
        "plt.plot(RMS_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJl46n3ruWnb"
      },
      "source": [
        "## Try it on the Notre Dame des Champs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpu79fHuuWvk"
      },
      "source": [
        "'''\n",
        "Define all parameters here\n",
        "Then execute the next cell\n",
        "'''\n",
        "path_input_source = '/content/SGD_ICP_PY/data/Notre_Dame_Des_Champs_1.ply'\n",
        "path_input_ref = '/content/SGD_ICP_PY/data/Notre_Dame_Des_Champs_2.ply'\n",
        "\n",
        "# Define the initial guess\n",
        "theta_init = np.array([-0.0,-0.0,0.0, 0.0, 0.0, 0.0])\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 5000\n",
        "\n",
        "# Consume the whole cloud before reshuffling, or resample at every batch step\n",
        "resample = False\n",
        "\n",
        "# Matching technique\n",
        "# Options are\n",
        "#   'identity': when matching is known\n",
        "#   'kdtree': Use sklearn KDTree built on the ref cloud\n",
        "#   'torch': Use matrix torch multiplication to compute distances\n",
        "matching_technique = 'kdtree' \n",
        "\n",
        "# Plot clouds at the end to see where the aligned cloud is w.r.t source and ref\n",
        "plot = False\n",
        "\n",
        "# Frequency to compute total RMS\n",
        "eval_every = 5\n",
        "\n",
        "RMS_list, roll_opt, pitch_opt, yaw_opt, T_opt = run_icp_pytorch_two_clouds(path_input_source,\n",
        "                    path_input_ref, theta_init, epochs,\n",
        "                    batch_size, resample, matching_technique,\n",
        "                    plot)\n",
        "\n",
        "plt.plot(RMS_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}